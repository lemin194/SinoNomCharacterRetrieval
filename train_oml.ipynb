{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "  num_classes=2139,\n",
    "  embed_dim=512,\n",
    "  decoder_embedding=384,\n",
    "  in_channels=1,\n",
    "  no_head = True,\n",
    "  model_name='caformer_s36.sail_in22k_ft_in1k_384',\n",
    "  \n",
    "  pretrained=True,\n",
    "  device='cuda',\n",
    "  lr=1e-5,\n",
    "  freeze_body=False,\n",
    "  warmup_steps=4,\n",
    "  # batchsize=32,\n",
    "  n_instances=2,\n",
    "  n_labels=56,\n",
    "  grad_accumulation_steps=4,\n",
    "  num_steps=1000, \n",
    "  num_epochs=100, \n",
    "  checkpointing_steps=50,\n",
    "  save_path='./working/trained_models/oml/caformer_s36.sail_in22k_ft_in1k_384_nohead',\n",
    "  pretrain_path='./working/trained_models/timm/caformer_s36.sail_in22k_ft_in1k_384',\n",
    ")\n",
    "config = dict(args._get_kwargs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from oml.datasets.base import DatasetWithLabels\n",
    "from oml.losses.triplet import TripletLossWithMiner\n",
    "from oml.miners.inbatch_all_tri import AllTripletsMiner\n",
    "from oml.miners.inbatch_nhard_tri import NHardTripletsMiner\n",
    "from oml.samplers.balance import BalanceSampler\n",
    "from oml.utils.download_mock_dataset import download_mock_dataset\n",
    "from retrieval.transform import *\n",
    "\n",
    "\n",
    "# dataset_root = \"input/classification/train\"\n",
    "# df_train = pd.read_csv('input/classification/train.csv').rename(columns={'image':'path'})\n",
    "# dataset_root = \"input/my_classify_data/full\"\n",
    "# df_train = pd.read_csv('input/my_classify_data/full.csv').rename(columns={'image':'path'})\n",
    "dataset_root = \"input/my_classify_data_v1/full\"\n",
    "df_train = pd.read_csv('input/my_classify_data_v1/full.csv').rename(columns={'image':'path'})\n",
    "label_counts = df_train['label'].value_counts()\n",
    "labels_to_keep = label_counts[label_counts >= 2].index\n",
    "df_train = df_train[df_train['label'].isin(labels_to_keep)]\n",
    "print(len(df_train))\n",
    "\n",
    "train_dataset = DatasetWithLabels(\n",
    "  df_train, dataset_root=None,\n",
    "  transform=train_transform,\n",
    ")\n",
    "\n",
    "\n",
    "# Online Hard Triplet Mining \n",
    "\n",
    "# criterion = TripletLossWithMiner(margin=0.1, miner=AllTripletsMiner(), need_logs=True)\n",
    "# criterion = TripletLossWithMiner(margin=0.1, miner=NHardTripletsMiner(1, 3), need_logs=True)\n",
    "criterion = TripletLossWithMiner(margin=None, miner=NHardTripletsMiner(1, 3), need_logs=True)\n",
    "\n",
    "\n",
    "# BalanceSampler for balanced positive and negative sampling.\n",
    "sampler = BalanceSampler(train_dataset.get_labels(), n_labels=args.n_labels, n_instances=args.n_instances)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers and LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval.oml.timm_extractor import TimmExtractor, create_timm_body\n",
    "from classification.ml_decoder.ml_decoder.ml_decoder import MLDecoder\n",
    "from fastai.vision.learner import _update_first_layer, has_pool_type, create_head, num_features_model\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from torch.optim import AdamW, SGD\n",
    "from lion_pytorch import Lion\n",
    "from torch.optim.lr_scheduler import LinearLR, SequentialLR, CosineAnnealingLR\n",
    "\n",
    "extractor = TimmExtractor(args.model_name, config)\n",
    "extractor.train()\n",
    "opt = Lion(extractor.parameters(), lr=args.lr, weight_decay=1e-2)\n",
    "# opt = AdamW(model.parameters(), lr=args.lr/10)\n",
    "# opt = SGD(model.parameters(), lr=args.lr)\n",
    "warmup = LinearLR(opt, start_factor=1/args.warmup_steps, total_iters=args.warmup_steps)\n",
    "reduce = CosineAnnealingLR(opt, T_max=args.num_epochs * len(train_loader))\n",
    "scheduler = SequentialLR(opt, [warmup, reduce], milestones=[args.warmup_steps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained timm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "body = create_timm_body(args.model_name, pretrained=False, n_in=args.in_channels)\n",
    "nf = num_features_model(body)\n",
    "ml_decoder_head = MLDecoder(args.num_classes, initial_num_features=nf, decoder_embedding=768)\n",
    "model = nn.Sequential(body, ml_decoder_head)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "if os.path.isfile(os.path.join(args.pretrain_path, 'pytorch_model.bin')):\n",
    "  best_score, state_dict = torch.load(os.path.join(args.pretrain_path, 'pytorch_model.bin'))\n",
    "  model.load_state_dict(state_dict)\n",
    "  print('loaded pretrain weights')\n",
    "  extractor.body = body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "min_score, max_score = 1e5, -1e5\n",
    "def eval_model(mode=1):\n",
    "  if mode == 0:\n",
    "    eval_model = extractor\n",
    "    db_vecs = []\n",
    "    eval_model.to(args.device)\n",
    "\n",
    "    for i in tqdm(range(252), position=0, leave=True):\n",
    "      db_img = cv2.imread('input/2d3d/database/pairs/%d.png' % i)\n",
    "      x = test_transform(image=db_img)['image'][[0], :, :]\n",
    "      x = x.to(args.device)[None]\n",
    "      eval_model.eval()\n",
    "      with torch.no_grad():\n",
    "        db_vec = eval_model(x)\n",
    "      db_vec = db_vec.detach().cpu().numpy()\n",
    "      db_vecs += [db_vec]\n",
    "\n",
    "    def score_query(q_vec):\n",
    "      db_scores = []\n",
    "      for i in range(252):\n",
    "        db_vec = db_vecs[i]\n",
    "        db_scores += [-((db_vec - q_vec) ** 2).sum()]\n",
    "      return db_scores\n",
    "      \n",
    "    labels = pd.read_csv('input/2d3d/labels.csv')\n",
    "\n",
    "    def eval_retrieve():\n",
    "      global min_score, max_score\n",
    "      min_score, max_score = 1e5, -1e5\n",
    "      scores = []\n",
    "      mean_scores = []\n",
    "      for i in tqdm(range(252), position=0, leave=True):\n",
    "        q_img = cv2.imread('input/2d3d/queries/%d.png' % i)\n",
    "        x = test_transform(image=q_img)['image'][[0], :, :]\n",
    "        x = x.to(args.device)[None]\n",
    "        eval_model.eval()\n",
    "        with torch.no_grad():\n",
    "          q_vec = eval_model(x)\n",
    "        q_vec = q_vec.detach().cpu().numpy()\n",
    "        db_scores = score_query(q_vec)\n",
    "        min_score = min(min_score, np.min(db_scores))\n",
    "        max_score = max(max_score, np.max(db_scores))\n",
    "        mean_scores += [np.mean(db_scores)]\n",
    "        rank = np.argsort(db_scores)[::-1]\n",
    "        \n",
    "        label = list(map(int, (labels.loc[labels['query'] == '%d.png' % i].label.iloc[0]).replace('.stl', '').split(',')))\n",
    "        min_rel = 1000\n",
    "        for rel in label:\n",
    "          min_rel = min(np.where(rank==rel)[0].item(), min_rel)\n",
    "        curr_score = 1 / (min_rel + 1) if min_rel < 5 else 0\n",
    "        # curr_score = any(rank[j]==i for j in range(1))\n",
    "        scores += [curr_score]\n",
    "      print(min_score, np.mean(mean_scores), max_score)\n",
    "      return np.mean(scores)\n",
    "    return eval_retrieve()\n",
    "    \n",
    "  \n",
    "  \n",
    "  db_vecs = []\n",
    "  eval_model = extractor\n",
    "  eval_model.cuda()\n",
    "\n",
    "  num_keys = len(os.listdir('input/2d3d/pairs/stl/pairs/'))\n",
    "  num_queries = len(os.listdir('input/2d3d/pairs/print/'))\n",
    "  for i in tqdm(range(num_keys), position=0, leave=True):\n",
    "    db_img = cv2.imread('input/2d3d/pairs/stl/pairs/%d.png' % i)\n",
    "    x = test_transform(image=db_img)['image'][[0], :, :]\n",
    "    x = x.cuda()[None]\n",
    "    eval_model.eval()\n",
    "    with torch.no_grad():\n",
    "      db_vec = eval_model(x)\n",
    "    db_vec = db_vec.detach().cpu().numpy()\n",
    "    db_vecs += [db_vec]\n",
    "\n",
    "  def score_query(q_vec):\n",
    "    db_scores = []\n",
    "    for i in range(num_keys):\n",
    "      db_vec = db_vecs[i]\n",
    "      db_scores += [-((db_vec - q_vec) ** 2).mean().item()]\n",
    "    return db_scores\n",
    "\n",
    "\n",
    "  def eval_retrieve():\n",
    "    scores = []\n",
    "    for i in tqdm(range(num_queries), position=0, leave=True):\n",
    "      q_img = cv2.imread('input/2d3d/pairs/print/%d.png' % i)\n",
    "      x = test_transform(image=q_img)['image'][[0], :, :]\n",
    "      x = x.cuda()[None]\n",
    "      eval_model.eval()\n",
    "      with torch.no_grad():\n",
    "        q_vec = eval_model(x)\n",
    "      q_vec = q_vec.detach().cpu().numpy()\n",
    "      db_scores = score_query(q_vec)\n",
    "      rank = np.argsort(db_scores)[::-1]\n",
    "      # print(np.where(rank==i)[0].item())\n",
    "      curr_score = any(rank[j]==i for j in range(1))\n",
    "      scores += [curr_score]\n",
    "    return np.mean(scores)\n",
    "  return eval_retrieve()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def save_model(step, best_score):\n",
    "  save_dir = os.path.join(args.save_path, 'ckpt%d'%step)\n",
    "  os.makedirs(args.save_path, exist_ok=True)\n",
    "  # torch.save((best_score, extractor.state_dict()), os.path.join(save_dir, 'pytorch_model.bin'))\n",
    "  torch.save((best_score, extractor.state_dict()), os.path.join(args.save_path, 'pytorch_model.bin'))\n",
    "\n",
    "def load_model(prev_score):\n",
    "  if os.path.isfile(os.path.join(args.save_path, 'pytorch_model.bin')):\n",
    "    best_score, state_dict = torch.load(os.path.join(args.save_path, 'pytorch_model.bin'))\n",
    "    if best_score > prev_score:\n",
    "      extractor.load_state_dict(state_dict)\n",
    "      print('loaded')\n",
    "      prev_score = best_score\n",
    "  return prev_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score, accuracy_score\n",
    "\n",
    "plot = True\n",
    "plot_every = 20\n",
    "\n",
    "losses = []\n",
    "accs = []\n",
    "grads = []\n",
    "model.to(args.device)\n",
    "step = 0\n",
    "best_score = 0.0\n",
    "last_score = 0.0\n",
    "\n",
    "best_score = load_model(best_score)\n",
    "last_score = best_score\n",
    "extractor.cuda()\n",
    "for epoch in range(1, args.num_epochs + 1):\n",
    "  pbar = tqdm(train_loader, position=0, leave=True)\n",
    "  \n",
    "  for batch in pbar:\n",
    "    extractor.train()\n",
    "    \n",
    "    for k in batch:\n",
    "      if k not in ['input_tensors', 'labels']: continue\n",
    "      if isinstance(batch[k], torch.Tensor):\n",
    "        batch[k] = batch[k].cuda()\n",
    "    embeddings = extractor(batch[\"input_tensors\"][:, [0]])\n",
    "    embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "    try:\n",
    "      loss = criterion(embeddings, batch[\"labels\"])\n",
    "      if torch.isinf(loss).sum().item() > 0:\n",
    "        print(\"Loss is inf\")\n",
    "        assert False, \"Loss is infinite\"\n",
    "      pass\n",
    "    except :\n",
    "      del batch\n",
    "      del embeddings\n",
    "      continue\n",
    "    loss.backward()\n",
    "    grad = torch.nn.utils.clip_grad_norm_(extractor.parameters(), 1.0)\n",
    "    # assert grad.item() > 1e-9, \"Grad is zero. Model not learning.\"\n",
    "    losses += [loss.item()]\n",
    "    grads += [grad.item()]\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "    opt.zero_grad()\n",
    "    step += 1\n",
    "    \n",
    "    \n",
    "    if plot and step % plot_every == 0: \n",
    "      clear_output(True)\n",
    "      plt.figure(figsize=(20, 5))\n",
    "      plt.subplot(131)\n",
    "      plt.title('loss=%.4f, grad=%.4f, lr=%.4e, best_score=%.4f, last_score=%.4f' % (\n",
    "      np.mean(losses[-32:]), np.mean(grads[-16:]), scheduler.get_last_lr()[-1], best_score, last_score))\n",
    "      plt.plot(losses)\n",
    "      plt.show()\n",
    "      \n",
    "    pbar.set_description_str('loss=%.4f, grad=%.4f, lr=%.4e, best_score=%.4f, last_score=%.4f' % (\n",
    "      np.mean(losses[-32:]), np.mean(grads[-16:]), scheduler.get_last_lr()[-1], best_score, last_score))\n",
    "    if step % args.checkpointing_steps == 0:\n",
    "      score = eval_model()\n",
    "      print(\"Score: %.4f\" % (score))\n",
    "      last_score = score\n",
    "      if score > best_score:\n",
    "        save_model(step, score)\n",
    "        best_score = score\n",
    "        print('New best: %.4f' % score)\n",
    "      # save_model(os.path.join(args.save_path, 'checkpoint_%d' % step))\n",
    "    del batch\n",
    "  \n",
    "  # score = eval_model()\n",
    "  # print(\"Score: %.4f\" % (score))\n",
    "  # last_score = score\n",
    "  # if score > best_score:\n",
    "  #   save_model(step, score)\n",
    "  #   best_score = score\n",
    "  #   print('New best: %.4f' % score)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
